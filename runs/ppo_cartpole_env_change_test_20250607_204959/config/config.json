{
  "experiment": {
    "env_import": "CartPole-v1",
    "name": "env_change_test",
    "description": "PPO on Carpole",
    "save_path": "../runs"
  },
  "environment": {
    "num_envs": 1,
    "custom_params": {
      "goal_velocity": 0.0,
      "height_reward_scale": 1.0
    },
    "wrappers": [
      {
        "name": "VecNormalize",
        "normalize_obs": true,
        "normalize_reward": true
      },
      {
        "name": "VecFrameStack",
        "n_stack": 1
      }
    ]
  },
  "algorithm": {
    "name": "PPO",
    "hyperparameters": {
      "learning_rate": 0.0003,
      "batch_size": 64,
      "n_epochs": 10,
      "n_steps": 2048,
      "gamma": 0.99,
      "gae_lambda": 0.95,
      "clip_range": 0.2,
      "clip_range_vf": null,
      "ent_coef": 0.0,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5
    },
    "policy_kwargs": {
      "net_arch": [
        64,
        64
      ],
      "activation_fn": "tanh"
    },
    "use_sde": false,
    "sde_sample_freq": -1
  },
  "training": {
    "total_timesteps": 30000,
    "eval_freq": 25000,
    "n_eval_episodes": 10,
    "eval_deterministic": true,
    "save_freq": 50000,
    "save_best_model": true,
    "early_stopping": {
      "enabled": true,
      "patience": 5,
      "min_delta": 10.0
    }
  },
  "logging": {
    "tensorboard": true,
    "wandb": false,
    "console_log_level": "INFO",
    "record_video": true,
    "video_freq": 50000,
    "video_length": 500,
    "custom_metrics": [
      "episode_height",
      "exploration_bonus"
    ]
  },
  "evaluation": {
    "episodes": 100,
    "deterministic": true,
    "render_mode": "rgb_array",
    "save_trajectories": false
  },
  "seed": 42,
  "deterministic_pytorch": true
}